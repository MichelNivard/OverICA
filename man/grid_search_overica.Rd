% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/functions.R
\name{grid_search_overica}
\alias{grid_search_overica}
\title{Grid Search over L1 Penalties for OverICA SEM}
\usage{
grid_search_overica(
  data,
  k,
  moment_func,
  error_cov = NULL,
  maskB = NULL,
  maskA = NULL,
  sigma = 0.01,
  third = TRUE,
  hidden_size = 10,
  n_batch = 1024,
  use_adam = TRUE,
  adam_epochs = 100,
  adam_lr = 0.01,
  use_lbfgs = TRUE,
  lbfgs_epochs = 50,
  lbfgs_lr = 1,
  lbfgs_max_iter = 20,
  lr_decay = 0.999,
  clip_grad = TRUE,
  num_runs = 1,
  initial_lambdaA = 0.01,
  initial_lambdaB = 0,
  num_iter = 3,
  threshold = 0.001,
  crit = "AIC",
  grid_steps = c(0.25, 1, 4)
)
}
\arguments{
\item{data}{A numeric matrix of observed data (n x p).}

\item{k}{Number of latent sources.}

\item{moment_func}{A function that takes a torch tensor (n_batch x p), along with moment indices
and a logical flag for third order moments, and returns a 1D torch tensor of computed moments.}

\item{error_cov}{Optional (p x p) covariance matrix for noise. If NULL, no error is added.}

\item{maskB}{Optional binary mask (p x p) for matrix B. A 1 indicates the entry is estimated,
and a 0 forces the entry to 0.}

\item{maskA}{Optional binary mask (p x k) for matrix A. A 1 indicates the entry is estimated,
and a 0 forces the entry to 0.}

\item{sigma}{Covariance penalty weight for the latent sources s (to encourage whitening).}

\item{third}{Do we consider the third moments, dont use if your distributions are suposed to be symetric.}

\item{hidden_size}{Number of hidden units in the neural network that maps z to s.}

\item{n_batch}{Batch size for the random z draws.}

\item{use_adam}{Logical; whether to run the Adam optimizer.}

\item{adam_epochs}{Number of epochs for Adam.}

\item{adam_lr}{Learning rate for Adam.}

\item{use_lbfgs}{Logical; whether to run the L-BFGS optimizer after Adam.}

\item{lbfgs_epochs}{Number of epochs for L-BFGS.}

\item{lbfgs_lr}{Learning rate for L-BFGS.}

\item{lbfgs_max_iter}{Maximum iterations per L-BFGS step.}

\item{lr_decay}{Multiplicative learning rate decay per epoch (set to 1 for no decay).}

\item{clip_grad}{Logical; whether to clip gradients.}

\item{num_runs}{Number of random restarts for the estimation.}

\item{initial_lambdaA}{Initial L1 penalty for matrix A.}

\item{initial_lambdaB}{Initial L1 penalty for matrix B.}

\item{num_iter}{Number of grid search iterations.}

\item{threshold}{Threashold at which to count a penalized parameter as zero (default is 0.001) for thr pseudo AIC or pseudo BIC}

\item{crit}{Which criterion to use, pseudo AIC ("AIC") or pseudo BIC ("BIC").}

\item{grid_steps}{Side of the innitial steps on the grid}
}
\value{
A list containing:
\describe{
\item{best_result}{The best estimation result, including the final matrices A and B and the final loss.}
\item{best_lambdaA}{The best L1 penalty chosen for matrix A.}
\item{best_lambdaB}{The best L1 penalty chosen for matrix B.}
\item{grid_losses}{A matrix of final losses from the last iteration of the grid search.}
}
}
\description{
This function performs a grid search over the L1 penalty hyperparameters for matrices A and B
in an OverICA SEM model. The underlying estimation function (e.g. \code{overica.moments.sem})
is called repeatedly with candidate penalty values. In the first iteration, candidate values
span one order of magnitude up and down from the initial values. In subsequent iterations,
the grid is refined using multiplicative factors of 0.5, 1, and 2 around the current best.
The candidate pair with the lowest final loss is selected and used as the center for the next iteration.
}
\examples{
\dontrun{
  # Assume 'data' is your observed data and 'torch_unique_24th_central_moments' is your moment function.
  grid_res <- grid_search_overica(data = data, k = 5,
                    moment_func = torch_central_moments,
                    initial_lambdaA = 0.01, initial_lambdaB = 0.00,
                    num_iter = 3)
  cat("Best lambdaA:", grid_res$best_lambdaA, "\n")
  cat("Best lambdaB:", grid_res$best_lambdaB, "\n")
}

}
